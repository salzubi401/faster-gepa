{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dspy\n",
        "\n",
        "# Disable disk and memory cache\n",
        "dspy.configure_cache(enable_disk_cache=False, enable_memory_cache=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from dspy.teleprompt import GEPA\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "os.environ[\"DSPY_CACHE_DIR\"] = \"/tmp/dspy_cache\"\n",
        "os.makedirs(\"/tmp/dspy_cache\", exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading HotpotQA dataset...\n",
            "Loaded 100 training examples, 50 validation examples, and 100 test examples.\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "from dspy.teleprompt import GEPA\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "import dspy\n",
        "from datasets import load_dataset\n",
        "from multi_llm_proposer import MultiLLMProposalFn\n",
        "\n",
        "# Initialize HotpotQA dataset\n",
        "def init_hotpotqa_dataset(num_train=100, num_val=50, num_test=100):\n",
        "    \"\"\"Load and prepare HotpotQA dataset for DSPy.\"\"\"\n",
        "    print(\"Loading HotpotQA dataset...\")\n",
        "    \n",
        "    # Load train split\n",
        "    train_dataset = load_dataset(\"hotpot_qa\", \"distractor\", split=\"train\")\n",
        "    train_dataset = train_dataset.select(range(0, min(num_train, len(train_dataset))))\n",
        "    \n",
        "    train_set = []\n",
        "    for example in train_dataset:\n",
        "        # Format context from HotpotQA\n",
        "        context_text = \"\\n\\n\".join([\n",
        "            f\"Document {i+1}: {title}\\n{' '.join(sentences)}\"\n",
        "            for i, (title, sentences) in enumerate(zip(example[\"context\"][\"title\"], example[\"context\"][\"sentences\"]))\n",
        "        ])\n",
        "        \n",
        "        train_set.append(\n",
        "            dspy.Example({\n",
        "                \"context\": context_text,\n",
        "                \"question\": example[\"question\"],\n",
        "                \"answer\": example[\"answer\"],\n",
        "            }).with_inputs(\"context\", \"question\")\n",
        "        )\n",
        "    \n",
        "    # Load validation split\n",
        "    val_dataset = load_dataset(\"hotpot_qa\", \"distractor\", split=\"validation\")\n",
        "    val_dataset = val_dataset.select(range(0, min(num_val, len(val_dataset))))\n",
        "    \n",
        "    val_set = []\n",
        "    for example in val_dataset:\n",
        "        context_text = \"\\n\\n\".join([\n",
        "            f\"Document {i+1}: {title}\\n{' '.join(sentences)}\"\n",
        "            for i, (title, sentences) in enumerate(zip(example[\"context\"][\"title\"], example[\"context\"][\"sentences\"]))\n",
        "        ])\n",
        "        \n",
        "        val_set.append(\n",
        "            dspy.Example({\n",
        "                \"context\": context_text,\n",
        "                \"question\": example[\"question\"],\n",
        "                \"answer\": example[\"answer\"],\n",
        "            }).with_inputs(\"context\", \"question\")\n",
        "        )\n",
        "    \n",
        "    # Load test split\n",
        "    test_dataset = load_dataset(\"hotpot_qa\", \"distractor\", split=\"validation\")\n",
        "    test_dataset = test_dataset.select(range(0, min(num_test, len(test_dataset))))\n",
        "    \n",
        "    test_set = []\n",
        "    for example in test_dataset:\n",
        "        context_text = \"\\n\\n\".join([\n",
        "            f\"Document {i+1}: {title}\\n{' '.join(sentences)}\"\n",
        "            for i, (title, sentences) in enumerate(zip(example[\"context\"][\"title\"], example[\"context\"][\"sentences\"]))\n",
        "        ])\n",
        "        \n",
        "        test_set.append(\n",
        "            dspy.Example({\n",
        "                \"context\": context_text,\n",
        "                \"question\": example[\"question\"],\n",
        "                \"answer\": example[\"answer\"],\n",
        "            }).with_inputs(\"context\", \"question\")\n",
        "        )\n",
        "    \n",
        "    print(f\"Loaded {len(train_set)} training examples, {len(val_set)} validation examples, and {len(test_set)} test examples.\")\n",
        "    return train_set, val_set, test_set\n",
        "\n",
        "train_set, val_set, test_set = init_hotpotqa_dataset(num_train=100, num_val=50, num_test=100)\n",
        "\n",
        "# Configure base LM\n",
        "lm = dspy.LM(\"openai/gpt-4.1-mini\", temperature=1, max_tokens=32000)\n",
        "dspy.configure(lm=lm)\n",
        "os.environ[\"DSPY_CACHE_DIR\"] = \"/tmp/dspy_cache\"\n",
        "os.makedirs(\"/tmp/dspy_cache\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the program for HotpotQA\n",
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer the question based on the provided context. Provide a concise and accurate answer.\"\"\"\n",
        "    context = dspy.InputField(desc=\"Context documents containing relevant information\")\n",
        "    question = dspy.InputField(desc=\"The question to answer\")\n",
        "    answer = dspy.OutputField(desc=\"The answer to the question\")\n",
        "\n",
        "program = dspy.ChainOfThought(GenerateAnswer)\n",
        "\n",
        "# Define metric with feedback (exact match for HotpotQA)\n",
        "def metric_with_feedback(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
        "    correct_answer = example['answer'].strip()\n",
        "    predicted_answer = prediction.answer.strip() if hasattr(prediction, 'answer') else str(prediction).strip()\n",
        "    \n",
        "    # Exact match scoring\n",
        "    score = int(correct_answer.lower() == predicted_answer.lower())\n",
        "    \n",
        "    feedback_text = \"\"\n",
        "    if score == 1:\n",
        "        feedback_text = f\"Your answer is correct. The correct answer is '{correct_answer}'.\"\n",
        "    else:\n",
        "        feedback_text = f\"Your answer is incorrect. You answered '{predicted_answer}', but the correct answer is '{correct_answer}'. \"\n",
        "        feedback_text += \"Make sure to carefully read the context documents and extract the exact information needed to answer the question. \"\n",
        "        feedback_text += \"Pay attention to details and ensure your answer matches the expected format.\"\n",
        "    \n",
        "    return dspy.Prediction(score=score, feedback=feedback_text)\n",
        "\n",
        "# Initialize MultiLLMProposalFn\n",
        "proposer = MultiLLMProposalFn(\n",
        "    proposal_lms=[\n",
        "        dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000),  # Reasoning model proposal\n",
        "        dspy.LM(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=1.0, max_tokens=16000), \n",
        "        dspy.LM(\"openrouter/google/gemini-2.5-flash\", temperature=0.6, max_tokens=16000),\n",
        "    ],\n",
        "    judge_lm=dspy.LM(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=1.0, max_tokens=16000), \n",
        "    merger_lm=dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000), \n",
        "    top_n=2,  \n",
        "    verbose=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:12:00 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 150 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
            "2025/11/06 17:12:00 INFO dspy.teleprompt.gepa.gepa: Using 50 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GEPA optimization with MultiLLMProposalFn for HotpotQA...\n",
            "Training set size: 100\n",
            "Validation set size: 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GEPA Optimization:   0%|          | 0/150 [00:00<?, ?rollouts/s]2025/11/06 17:12:10 INFO dspy.evaluate.evaluate: Average Metric: 11.0 / 50 (22.0%)\n",
            "2025/11/06 17:12:10 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.22\n",
            "GEPA Optimization:  33%|███▎      | 50/150 [00:09<00:18,  5.34rollouts/s]2025/11/06 17:12:10 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.22\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 2.00 / 5 (40.0%): 100%|██████████| 5/5 [00:02<00:00,  2.39it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:12:12 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 5 (40.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================================================\n",
            "Processing component: predict\n",
            "============================================================\n",
            "\n",
            "Generating 3 proposals in parallel...\n",
            "  [Proposal 3] Generated with openrouter/google/gemini-2.5-flash\n",
            "  [Proposal 2] Generated with openrouter/anthropic/claude-sonnet-4.5\n",
            "  [Proposal 1] Generated with openai/gpt-5\n",
            "\n",
            "Scoring 3 proposals with judge LLM...\n",
            "  [Proposal 1] Score: 86.0/100 (Dataset: 44.0, Quality: 42.0)\n",
            "  [Proposal 2] Score: 74.0/100 (Dataset: 38.0, Quality: 36.0)\n",
            "  [Proposal 3] Score: 40.0/100 (Dataset: 18.0, Quality: 22.0)\n",
            "\n",
            "Selected top 2 proposals for merging:\n",
            "  1. Score: 86.0/100\n",
            "  2. Score: 74.0/100\n",
            "\n",
            "Merging top 2 proposals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:14:46 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: Task: Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Input:\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single question whose answer is found in the context\n",
            "\n",
            "Rules and strategy:\n",
            "1) Use only information explicitly stated in the context. Do not use outside knowledge or infer beyond what is written.\n",
            "2) Identify the document(s) that directly satisfy the question’s constraint(s) (e.g., role, gender, title, year). Prefer the document that explicitly links the entity to the asked role/attribute (the authoritative relevant document).\n",
            "3) Cross-check other documents only to select the most specific and complete form that matches the asked linkage (e.g., include middle names when that full form appears in the document identifying the role/attribute or a clearly linked bio).\n",
            "4) Extract the minimal exact text span that directly answers the question. Do not paraphrase or reword. Preserve capitalization, diacritics, spacing, and hyphenation exactly as in the source.\n",
            "5) Match the expected granularity and phrasing exactly:\n",
            "   - Ages: use the hyphenated form as written (e.g., “16-year-old”).\n",
            "   - “In what year”: return only the 4-digit year (e.g., “2006”).\n",
            "   - Names tied to roles/attributes: return the full name as given in the authoritative relevant document (include middle names if present there).\n",
            "6) Apply filters precisely (e.g., if the question specifies “male actor,” select only the male actor; if it specifies a role like “narrator,” use the name version tied to that role).\n",
            "7) Do not add qualifiers or extra text (e.g., avoid “about,” “approximately,” explanations, punctuation not in the answer, or quotes unless they are part of the answer).\n",
            "8) Output only the answer string. Do not include reasoning or any additional text.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Merged instruction created (1824 chars)\n",
            "  Rationale: 1) Unique elements taken from each proposal and why:\n",
            "- From Proposal 1:\n",
            "  - Role/attribute-linked disambiguation and the idea of an “authoritative relevant document” to decide the correct, fully speci...\n",
            "\n",
            "[Final] New instruction for predict:\n",
            "  Task: Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Input:\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single ques...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:14:49 INFO dspy.evaluate.evaluate: Average Metric: 4.0 / 5 (80.0%)\n",
            "2025/11/06 17:14:49 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score 4 is better than old score 2. Continue to full eval and add to candidate pool.\n",
            "2025/11/06 17:14:55 INFO dspy.evaluate.evaluate: Average Metric: 31.0 / 50 (62.0%)\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.62\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.62\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.68\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {1}, {0, 1}]\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.62\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.62\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.62\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
            "GEPA Optimization:  73%|███████▎  | 110/150 [02:54<01:12,  1.80s/rollouts]2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 2: No merge candidates found\n",
            "2025/11/06 17:14:55 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 1 score: 0.62\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 5.00 / 5 (100.0%): 100%|██████████| 5/5 [00:03<00:00,  1.45it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:14:58 INFO dspy.evaluate.evaluate: Average Metric: 5.0 / 5 (100.0%)\n",
            "2025/11/06 17:14:58 INFO dspy.teleprompt.gepa.gepa: Iteration 2: All subsample scores perfect. Skipping.\n",
            "2025/11/06 17:14:58 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Reflective mutation did not propose a new candidate\n",
            "GEPA Optimization:  77%|███████▋  | 115/150 [02:57<01:00,  1.73s/rollouts]2025/11/06 17:14:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 1 score: 0.62\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 4.00 / 5 (80.0%): 100%|██████████| 5/5 [00:02<00:00,  2.28it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:15:00 INFO dspy.evaluate.evaluate: Average Metric: 4.0 / 5 (80.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================================================\n",
            "Processing component: predict\n",
            "============================================================\n",
            "\n",
            "Generating 3 proposals in parallel...\n",
            "  [Proposal 3] Generated with openrouter/google/gemini-2.5-flash\n",
            "  [Proposal 2] Generated with openrouter/anthropic/claude-sonnet-4.5\n",
            "  [Proposal 1] Generated with openai/gpt-5\n",
            "\n",
            "Scoring 3 proposals with judge LLM...\n",
            "  [Proposal 1] Score: 74.0/100 (Dataset: 38.0, Quality: 36.0)\n",
            "  [Proposal 2] Score: 60.0/100 (Dataset: 28.0, Quality: 32.0)\n",
            "  [Proposal 3] Score: 50.0/100 (Dataset: 22.0, Quality: 28.0)\n",
            "\n",
            "Selected top 2 proposals for merging:\n",
            "  1. Score: 74.0/100\n",
            "  2. Score: 60.0/100\n",
            "\n",
            "Merging top 2 proposals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:19:07 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for predict: Task\n",
            "Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Inputs\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single question whose answer is found in the context\n",
            "\n",
            "Rules and strategy\n",
            "1) Use only information explicitly stated in the context. Do not use outside knowledge or infer beyond what is written.\n",
            "\n",
            "2) Select the authoritative relevant document:\n",
            "   - Find the document that explicitly links the asked entity to the required role/attribute/time/filter.\n",
            "   - Use other documents only to disambiguate entities or confirm which document is authoritative; never to augment or rewrite the answer.\n",
            "\n",
            "3) Extract a single, minimal, contiguous exact text span from the authoritative document.\n",
            "   - You may extract from the middle of a sentence; do not force full sentences.\n",
            "   - Do not join non-adjacent fragments or reformat content.\n",
            "   - Preserve capitalization, diacritics, hyphenation, internal punctuation, conjunctions, and spacing exactly. Include terminal punctuation only if it is part of the chosen span.\n",
            "\n",
            "4) Match the expected granularity and phrasing exactly:\n",
            "   - Years: return only the 4-digit year (select just the year substring, not the full date).\n",
            "   - Ages: use the form as written; if the text says “at the age of N”, return “N”; if written as “16-year-old”, return it as written.\n",
            "   - Names tied to roles/attributes: return the name exactly as it appears in the authoritative span (include middle names only if they appear in that span).\n",
            "\n",
            "5) Lists, lineups, and sets (members/cast/participants/etc.):\n",
            "   - Copy the single contiguous phrase that lists the items from the authoritative document; do not reformat into a simple list or expand/shorten names.\n",
            "   - Keep embedded role descriptors that are inside the minimal contiguous phrase needed to satisfy the question’s constraints (e.g., “longtime lead guitarist Kirk Hammett”).\n",
            "   - Trim only leading/trailing words not required to answer (e.g., introductory clauses like “Metallica’s current lineup comprises …”), while maintaining a contiguous span for the actual answer.\n",
            "\n",
            "6) Apply filters precisely (e.g., gender, role, time). If multiple candidates appear, choose the contiguous span that matches the specified filter and linkage. Do not replace or expand names/forms using other documents if it would break contiguity or exact-span extraction.\n",
            "\n",
            "7) Yes/No questions: output only “yes” or “no” in plain text.\n",
            "\n",
            "8) Output only the answer string. Do not include reasoning, explanations, or quotes.\n",
            "\n",
            "Strategy\n",
            "A) Parse the question for entity, role/attribute, time, and filters.\n",
            "B) Locate the document that explicitly ties those constraints together.\n",
            "C) In that document, find the exact sentence/fragment that states the answer.\n",
            "D) Narrow to the smallest contiguous substring that fully satisfies the question and filter requirements.\n",
            "E) Preflight copy-paste check: confirm the answer is (i) an exact copy of a single contiguous span from the authoritative document, (ii) not reformatted or synthesized across documents, and (iii) matches the required granularity.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Merged instruction created (3106 chars)\n",
            "  Rationale: 1) Unique elements taken and why\n",
            "- From Proposal 1:\n",
            "  - Strict single, minimal, contiguous exact text span rule to prevent non-contiguous synthesis—the root cause of the failure.\n",
            "  - Preservation of i...\n",
            "\n",
            "[Final] New instruction for predict:\n",
            "  Task\n",
            "Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Inputs\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single quest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:19:09 INFO dspy.evaluate.evaluate: Average Metric: 4.0 / 5 (80.0%)\n",
            "2025/11/06 17:19:09 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New subsample score 4 is not better than old score 4, skipping\n",
            "GEPA Optimization:  83%|████████▎ | 125/150 [07:08<02:20,  5.62s/rollouts]2025/11/06 17:19:09 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 1 score: 0.62\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 2.00 / 5 (40.0%): 100%|██████████| 5/5 [00:02<00:00,  1.81it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:19:12 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 5 (40.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================================================\n",
            "Processing component: predict\n",
            "============================================================\n",
            "\n",
            "Generating 3 proposals in parallel...\n",
            "  [Proposal 3] Generated with openrouter/google/gemini-2.5-flash\n",
            "  [Proposal 2] Generated with openrouter/anthropic/claude-sonnet-4.5\n",
            "  [Proposal 1] Generated with openai/gpt-5\n",
            "\n",
            "Scoring 3 proposals with judge LLM...\n",
            "  [Proposal 1] Score: 79.5/100 (Dataset: 41.5, Quality: 38.0)\n",
            "  [Proposal 2] Score: 60.0/100 (Dataset: 28.0, Quality: 32.0)\n",
            "  [Proposal 3] Score: 70.0/100 (Dataset: 34.0, Quality: 36.0)\n",
            "\n",
            "Selected top 2 proposals for merging:\n",
            "  1. Score: 79.5/100\n",
            "  2. Score: 70.0/100\n",
            "\n",
            "Merging top 2 proposals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:23:06 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for predict: Task: Using only the provided numbered documents, answer the question with a single, concise answer string.\n",
            "\n",
            "Rules:\n",
            "1) Use only what is explicitly stated in the documents. No outside knowledge or inference.\n",
            "2) Locate the authoritative evidence:\n",
            "   - Prefer a single document that satisfies all question constraints (role/attribute/date/place/etc.).\n",
            "   - If no single document satisfies all constraints, use one document (e.g., a list) to identify candidates and other document(s) to apply filters (e.g., nationality, death date) to select the correct entity.\n",
            "3) Final answer span:\n",
            "   - Extract a minimal, contiguous, verbatim text span from one document only.\n",
            "   - Choose that document to be the one that provides the most specific, distinguishing constraints relevant to the question (or the clearest linkage if one doc alone satisfies all constraints).\n",
            "4) Names and forms:\n",
            "   - People: Return the full name as given in the chosen document. If a clearly linked document for the same person provides a more complete form (e.g., includes middle names) and that document supplies the distinguishing constraints used to identify the person, prefer that more complete form from that document.\n",
            "   - Organizations: Use the exact form that appears in the document establishing the asked relationship. Do not add/remove corporate suffixes or variants from other documents.\n",
            "   - If the source expresses the needed answer as a coupled role+name phrase (e.g., “dancer Gregory Hines”) and the question expects that linkage, return that full coupled phrase.\n",
            "5) Match granularity and phrasing exactly:\n",
            "   - Ages: keep hyphenation as written (e.g., “16-year-old”).\n",
            "   - “In what year”: return only the 4-digit year.\n",
            "   - Yes/No questions: return exactly “yes” or “no” in lowercase.\n",
            "6) Apply filters precisely (e.g., gender, nationality, “other member,” specific role like “narrator”). Ensure the selected entity satisfies all stated filters.\n",
            "7) Preserve capitalization, diacritics, spacing, punctuation, and hyphenation exactly as written in the source span.\n",
            "8) Do not add qualifiers or extra text. Output only the answer string.\n",
            "\n",
            "Checklist before answering:\n",
            "- Parse all explicit constraints in the question.\n",
            "- Identify candidate docs; select the document whose span you will quote based on Rule 3.\n",
            "- If multiple name/organization variants exist, pick the exact form from the document that best satisfies the combined constraints/linkage needed by the question.\n",
            "- Extract the smallest span that fully answers the question.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Merged instruction created (2507 chars)\n",
            "  Rationale: 1) Unique elements taken and why:\n",
            "- From Proposal 1:\n",
            "  - Authoritative-document focus and cross-document disambiguation with “final answer must be verbatim from one document” to prevent synthesis erro...\n",
            "\n",
            "[Final] New instruction for predict:\n",
            "  Task: Using only the provided numbered documents, answer the question with a single, concise answer string.\n",
            "\n",
            "Rules:\n",
            "1) Use only what is explicitly stated in the documents. No outside knowledge or infe...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:23:09 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 5 (40.0%)\n",
            "2025/11/06 17:23:09 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New subsample score 2 is not better than old score 2, skipping\n",
            "GEPA Optimization:  90%|█████████ | 135/150 [11:08<02:17,  9.14s/rollouts]2025/11/06 17:23:09 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 1 score: 0.62\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 3.00 / 5 (60.0%): 100%|██████████| 5/5 [00:02<00:00,  2.11it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:23:11 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 5 (60.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================================================\n",
            "Processing component: predict\n",
            "============================================================\n",
            "\n",
            "Generating 3 proposals in parallel...\n",
            "  [Proposal 3] Generated with openrouter/google/gemini-2.5-flash\n",
            "  [Proposal 2] Generated with openrouter/anthropic/claude-sonnet-4.5\n",
            "  [Proposal 1] Generated with openai/gpt-5\n",
            "\n",
            "Scoring 3 proposals with judge LLM...\n",
            "  [Proposal 1] Score: 83.0/100 (Dataset: 40.0, Quality: 43.0)\n",
            "  [Proposal 2] Score: 53.0/100 (Dataset: 22.0, Quality: 31.0)\n",
            "  [Proposal 3] Score: 54.0/100 (Dataset: 26.0, Quality: 28.0)\n",
            "\n",
            "Selected top 2 proposals for merging:\n",
            "  1. Score: 83.0/100\n",
            "  2. Score: 54.0/100\n",
            "\n",
            "Merging top 2 proposals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:27:30 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for predict: Task: Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Input:\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single question whose answer is found in the context\n",
            "\n",
            "Rules and strategy:\n",
            "1) Parse the question to determine:\n",
            "   - The requested answer type (e.g., person’s name, year, genus, family, place).\n",
            "   - All constraints (role/attribute, gender, title, location, time, singular vs plural).\n",
            "\n",
            "2) Identify the authoritative relevant document(s): those that directly and explicitly link the requested entity type to the asked role/attribute/location/time in one place. Prefer the document that states the exact linkage the question asks about.\n",
            "\n",
            "3) Cross-check other documents only to:\n",
            "   - Verify the entity satisfies all constraints.\n",
            "   - Select the most specific and complete form that matches the asked linkage (e.g., include middle names when they appear in the role-linking document or a clearly linked bio).\n",
            "\n",
            "4) Entity type fidelity:\n",
            "   - Answer with an entity explicitly labeled as the requested type in the authoritative document (e.g., if asked for a “genus,” return a genus; if asked for a “family,” return a family).\n",
            "   - For phrases like “genus of moth,” treat “genus” as the requested type and return a genus (do not substitute a broader or narrower rank).\n",
            "\n",
            "5) Name-form selection for roles/attributes:\n",
            "   - Use the name form that appears in the same sentence or clause that establishes the requested role/attribute.\n",
            "   - If the role/attribute is established only in a clearly linked bio, use the name form given there (include middle names if present).\n",
            "   - When both a stage/pseudonym and a birth/legal name exist, choose the one directly tied to the role/attribute per the above rule.\n",
            "\n",
            "6) Disambiguation and tie-breaking (return exactly one answer):\n",
            "   - Apply all filters precisely (role, gender, location, title, year).\n",
            "   - Prefer the entity mention that most exclusively matches the constraints (e.g., found only in the asked location vs. multiple locations).\n",
            "   - Prefer the document that states all required constraints together (same sentence/section).\n",
            "   - Prefer the most specific, complete form from the authoritative document (e.g., full legal name with middle names if present there).\n",
            "   - If candidates remain tied, choose the one with the minimal exact span that still fully answers the question.\n",
            "   - Never list multiple candidates; select a single best-supported answer.\n",
            "\n",
            "7) Extraction and formatting:\n",
            "   - Extract the minimal exact text span that directly answers the question. Do not paraphrase or reword. Preserve capitalization, diacritics, spacing, and hyphenation exactly as in the source.\n",
            "   - Match the expected granularity and phrasing exactly:\n",
            "     • Ages: use the hyphenated form as written (e.g., “16-year-old”).\n",
            "     • “In what year”: return only the 4-digit year (e.g., “2006”).\n",
            "     • Names tied to roles/attributes: return the full name exactly as in the role-linking document (include middle names if present there).\n",
            "   - Do not add qualifiers or extra text (no “about,” “approximately,” explanations, punctuation not in the source, or quotes unless part of the source span).\n",
            "\n",
            "8) Output only the answer string. Do not include reasoning or any additional text.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Merged instruction created (3285 chars)\n",
            "  Rationale: 1) Unique elements taken and why:\n",
            "   - From Proposal 1:\n",
            "     • Authoritative relevant document concept with explicit linkage: Ensures selection of the document that directly ties the entity to the ask...\n",
            "\n",
            "[Final] New instruction for predict:\n",
            "  Task: Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Input:\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single ques...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:27:37 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 5 (60.0%)\n",
            "2025/11/06 17:27:37 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New subsample score 3 is not better than old score 3, skipping\n",
            "GEPA Optimization:  97%|█████████▋| 145/150 [15:36<01:04, 12.96s/rollouts]2025/11/06 17:27:37 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 1 score: 0.62\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 5.00 / 5 (100.0%): 100%|██████████| 5/5 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:27:39 INFO dspy.evaluate.evaluate: Average Metric: 5.0 / 5 (100.0%)\n",
            "2025/11/06 17:27:39 INFO dspy.teleprompt.gepa.gepa: Iteration 6: All subsample scores perfect. Skipping.\n",
            "2025/11/06 17:27:39 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Reflective mutation did not propose a new candidate\n",
            "GEPA Optimization:  97%|█████████▋| 145/150 [15:38<00:32,  6.47s/rollouts]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Optimized program instructions:\n",
            "Task: Answer the question using only the provided context documents. Output a single, concise answer string.\n",
            "\n",
            "Input:\n",
            "- context: Numbered documents (Document 1, Document 2, …)\n",
            "- question: A single question whose answer is found in the context\n",
            "\n",
            "Rules and strategy:\n",
            "1) Use only information explicitly stated in the context. Do not use outside knowledge or infer beyond what is written.\n",
            "2) Identify the document(s) that directly satisfy the question’s constraint(s) (e.g., role, gender, title, year). Prefer the document that explicitly links the entity to the asked role/attribute (the authoritative relevant document).\n",
            "3) Cross-check other documents only to select the most specific and complete form that matches the asked linkage (e.g., include middle names when that full form appears in the document identifying the role/attribute or a clearly linked bio).\n",
            "4) Extract the minimal exact text span that directly answers the question. Do not paraphrase or reword. Preserve capitalization, diacritics, spacing, and hyphenation exactly as in the source.\n",
            "5) Match the expected granularity and phrasing exactly:\n",
            "   - Ages: use the hyphenated form as written (e.g., “16-year-old”).\n",
            "   - “In what year”: return only the 4-digit year (e.g., “2006”).\n",
            "   - Names tied to roles/attributes: return the full name as given in the authoritative relevant document (include middle names if present there).\n",
            "6) Apply filters precisely (e.g., if the question specifies “male actor,” select only the male actor; if it specifies a role like “narrator,” use the name version tied to that role).\n",
            "7) Do not add qualifiers or extra text (e.g., avoid “about,” “approximately,” explanations, punctuation not in the answer, or quotes unless they are part of the answer).\n",
            "8) Output only the answer string. Do not include reasoning or any additional text.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run GEPA optimization with MultiLLMProposalFn\n",
        "optimizer = GEPA(\n",
        "    metric=metric_with_feedback,\n",
        "    reflection_lm=dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000),  \n",
        "    max_full_evals=1,\n",
        "    num_threads=32,\n",
        "    track_stats=True,\n",
        "    reflection_minibatch_size=5,\n",
        "    instruction_proposer=proposer,\n",
        ")\n",
        "\n",
        "print(\"Starting GEPA optimization with MultiLLMProposalFn for HotpotQA...\")\n",
        "print(f\"Training set size: {len(train_set)}\")\n",
        "print(f\"Validation set size: {len(val_set)}\")\n",
        "\n",
        "optimized_program = optimizer.compile(\n",
        "    program,\n",
        "    trainset=train_set,\n",
        "    valset=val_set,\n",
        ")\n",
        "\n",
        "print(\"\\nOptimized program instructions:\")\n",
        "print(optimized_program.predict.signature.instructions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating optimized program on test set...\n",
            "Average Metric: 65.00 / 100 (65.0%): 100%|██████████| 100/100 [00:08<00:00, 11.98it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:27:48 INFO dspy.evaluate.evaluate: Average Metric: 65 / 100 (65.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>example_answer</th>\n",
              "      <th>reasoning</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>&lt;lambda&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Document 1: Ed Wood (film) Ed Wood is a 1994 American biographical...</td>\n",
              "      <td>Were Scott Derrickson and Ed Wood of the same nationality?</td>\n",
              "      <td>yes</td>\n",
              "      <td>Document 2 states Scott Derrickson is an American director. Docume...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Document 1: Meet Corliss Archer Meet Corliss Archer, a program fro...</td>\n",
              "      <td>What government position was held by the woman who portrayed Corli...</td>\n",
              "      <td>Chief of Protocol</td>\n",
              "      <td>The woman who portrayed Corliss Archer in the film Kiss and Tell (...</td>\n",
              "      <td>United States ambassador to Ghana and to Czechoslovakia and Chief ...</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Document 1: Andre Norton Award The Andre Norton Award for Young Ad...</td>\n",
              "      <td>What science fantasy young adult series, told in first person, has...</td>\n",
              "      <td>Animorphs</td>\n",
              "      <td>Document 9 states that \"Animorphs is a science fantasy series of y...</td>\n",
              "      <td>Animorphs</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Document 1: Esma Sultan (daughter of Abdülaziz) Esma Sultan (21 Ma...</td>\n",
              "      <td>Are the Laleli Mosque and Esma Sultan Mansion located in the same ...</td>\n",
              "      <td>no</td>\n",
              "      <td>Document 6 states that the Laleli Mosque is located in Laleli, Fat...</td>\n",
              "      <td>No</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Document 1: Just Another Romantic Wrestling Comedy Just Another Ro...</td>\n",
              "      <td>The director of the romantic comedy \"Big Stone Gap\" is based in wh...</td>\n",
              "      <td>Greenwich Village, New York City</td>\n",
              "      <td>Document 10 states that Adriana Trigiani wrote and directed \"Big S...</td>\n",
              "      <td>Greenwich Village, New York City</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Document 1: Scott's Run Nature Preserve Scott's Run Nature Preserv...</td>\n",
              "      <td>Tysons Galleria is located in what county?</td>\n",
              "      <td>Fairfax County</td>\n",
              "      <td>Document 2 states that Tysons Galleria is located at 2001 Internat...</td>\n",
              "      <td>Fairfax County</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Document 1: Cardinal Health Cardinal Health, Inc. is a Fortune 500...</td>\n",
              "      <td>Bordan Tkachuk was the CEO of a company that provides what sort of...</td>\n",
              "      <td>IT products and services</td>\n",
              "      <td>Document 4 states that Bordan Tkachuk was the former CEO of Viglen...</td>\n",
              "      <td>IT products and services</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Document 1: Aryanto Yuniawan Aryanto Yuniawan (born June 18, 1977 ...</td>\n",
              "      <td>Which filmmaker was known for animation, Lev Yilmaz or Pamela B. G...</td>\n",
              "      <td>Levni Yilmaz</td>\n",
              "      <td>Document 7 states that Levni Yilmaz (born 1973) is a San Francisco...</td>\n",
              "      <td>Lev Yilmaz</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Document 1: Visa policy of Hong Kong The visa policy of Hong Kong ...</td>\n",
              "      <td>In which city is the ambassador of the Rabat-Salé-Kénitra administ...</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>Document 8 states that the Moroccan ambassador in Beijing is the o...</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Document 1: Fuding Railway Station Fuding Railway Station () is a ...</td>\n",
              "      <td>Are Yingkou and Fuding the same level of city?</td>\n",
              "      <td>no</td>\n",
              "      <td>Document 2 states that Yingkou is a prefecture-level city of Liaon...</td>\n",
              "      <td>No</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  context  \\\n",
              "0   Document 1: Ed Wood (film) Ed Wood is a 1994 American biographical...   \n",
              "1   Document 1: Meet Corliss Archer Meet Corliss Archer, a program fro...   \n",
              "2   Document 1: Andre Norton Award The Andre Norton Award for Young Ad...   \n",
              "3   Document 1: Esma Sultan (daughter of Abdülaziz) Esma Sultan (21 Ma...   \n",
              "4   Document 1: Just Another Romantic Wrestling Comedy Just Another Ro...   \n",
              "..                                                                    ...   \n",
              "95  Document 1: Scott's Run Nature Preserve Scott's Run Nature Preserv...   \n",
              "96  Document 1: Cardinal Health Cardinal Health, Inc. is a Fortune 500...   \n",
              "97  Document 1: Aryanto Yuniawan Aryanto Yuniawan (born June 18, 1977 ...   \n",
              "98  Document 1: Visa policy of Hong Kong The visa policy of Hong Kong ...   \n",
              "99  Document 1: Fuding Railway Station Fuding Railway Station () is a ...   \n",
              "\n",
              "                                                                 question  \\\n",
              "0              Were Scott Derrickson and Ed Wood of the same nationality?   \n",
              "1   What government position was held by the woman who portrayed Corli...   \n",
              "2   What science fantasy young adult series, told in first person, has...   \n",
              "3   Are the Laleli Mosque and Esma Sultan Mansion located in the same ...   \n",
              "4   The director of the romantic comedy \"Big Stone Gap\" is based in wh...   \n",
              "..                                                                    ...   \n",
              "95                             Tysons Galleria is located in what county?   \n",
              "96  Bordan Tkachuk was the CEO of a company that provides what sort of...   \n",
              "97  Which filmmaker was known for animation, Lev Yilmaz or Pamela B. G...   \n",
              "98  In which city is the ambassador of the Rabat-Salé-Kénitra administ...   \n",
              "99                         Are Yingkou and Fuding the same level of city?   \n",
              "\n",
              "                      example_answer  \\\n",
              "0                                yes   \n",
              "1                  Chief of Protocol   \n",
              "2                          Animorphs   \n",
              "3                                 no   \n",
              "4   Greenwich Village, New York City   \n",
              "..                               ...   \n",
              "95                    Fairfax County   \n",
              "96          IT products and services   \n",
              "97                      Levni Yilmaz   \n",
              "98                           Beijing   \n",
              "99                                no   \n",
              "\n",
              "                                                                reasoning  \\\n",
              "0   Document 2 states Scott Derrickson is an American director. Docume...   \n",
              "1   The woman who portrayed Corliss Archer in the film Kiss and Tell (...   \n",
              "2   Document 9 states that \"Animorphs is a science fantasy series of y...   \n",
              "3   Document 6 states that the Laleli Mosque is located in Laleli, Fat...   \n",
              "4   Document 10 states that Adriana Trigiani wrote and directed \"Big S...   \n",
              "..                                                                    ...   \n",
              "95  Document 2 states that Tysons Galleria is located at 2001 Internat...   \n",
              "96  Document 4 states that Bordan Tkachuk was the former CEO of Viglen...   \n",
              "97  Document 7 states that Levni Yilmaz (born 1973) is a San Francisco...   \n",
              "98  Document 8 states that the Moroccan ambassador in Beijing is the o...   \n",
              "99  Document 2 states that Yingkou is a prefecture-level city of Liaon...   \n",
              "\n",
              "                                                              pred_answer  \\\n",
              "0                                                                     Yes   \n",
              "1   United States ambassador to Ghana and to Czechoslovakia and Chief ...   \n",
              "2                                                               Animorphs   \n",
              "3                                                                      No   \n",
              "4                                        Greenwich Village, New York City   \n",
              "..                                                                    ...   \n",
              "95                                                         Fairfax County   \n",
              "96                                               IT products and services   \n",
              "97                                                             Lev Yilmaz   \n",
              "98                                                                Beijing   \n",
              "99                                                                     No   \n",
              "\n",
              "   <lambda>  \n",
              "0    ✔️ [1]  \n",
              "1    ✔️ [0]  \n",
              "2    ✔️ [1]  \n",
              "3    ✔️ [1]  \n",
              "4    ✔️ [1]  \n",
              "..      ...  \n",
              "95   ✔️ [1]  \n",
              "96   ✔️ [1]  \n",
              "97   ✔️ [0]  \n",
              "98   ✔️ [1]  \n",
              "99   ✔️ [1]  \n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final accuracy: 65.0%\n",
            "Correct: 65 / 100\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the optimized program on test set\n",
        "evaluate = dspy.Evaluate(\n",
        "    devset=test_set,\n",
        "    metric=lambda example, prediction, trace=None, pred_name=None, pred_trace=None: \n",
        "        int(example['answer'].strip().lower() == prediction.answer.strip().lower()) if hasattr(prediction, 'answer') else 0,\n",
        "    num_threads=32,\n",
        "    display_table=True,\n",
        "    display_progress=True\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating optimized program on test set...\")\n",
        "result = evaluate(optimized_program)\n",
        "print(f\"\\nFinal accuracy: {result.score}%\")\n",
        "print(f\"Correct: {result.score * len(test_set) / 100:.0f} / {len(test_set)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:38:00 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 150 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
            "2025/11/06 17:38:00 INFO dspy.teleprompt.gepa.gepa: Using 50 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GEPA optimization with DEFAULT proposer for comparison...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GEPA Optimization:   0%|          | 0/150 [00:00<?, ?rollouts/s]2025/11/06 17:38:08 INFO dspy.evaluate.evaluate: Average Metric: 10.0 / 50 (20.0%)\n",
            "2025/11/06 17:38:08 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.2\n",
            "GEPA Optimization:  33%|███▎      | 50/150 [00:08<00:16,  6.02rollouts/s]2025/11/06 17:38:08 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 1.00 / 3 (33.3%): 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:38:10 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:38:51 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: Task: Answer a single question using only the provided “context” documents. Return a concise, exact answer string with no extra text.\n",
            "\n",
            "Guidelines:\n",
            "1) Use only information explicitly stated in the provided context. Do not rely on outside knowledge or make inferences beyond what is written.\n",
            "2) Find the document(s) that directly address the entity and attribute in the question. Cross-reference documents when necessary, but prefer the source that explicitly ties the attribute to the entity as framed by the question.\n",
            "3) Return the answer in the most precise, fully specified form present in the context:\n",
            "   - For names: include full names (e.g., middle names) if given (e.g., “Walter Darwin Coy” rather than “Walter Coy” when the full form is provided for the same person).\n",
            "   - For ages: match the exact phrasing used in the context (e.g., “16-year-old” rather than “16”).\n",
            "   - For years: return only the 4-digit year (e.g., “2006”) unless the question asks for more detail.\n",
            "   - Preserve capitalization, punctuation, diacritics, hyphens, and stylization exactly as in the source text.\n",
            "4) Do not add qualifiers, approximations, or explanations. Avoid words like “approximately,” “likely,” or “about.” Provide no reasoning or restatement of the question—only the answer.\n",
            "5) If multiple candidate answers exist, choose the one:\n",
            "   - Most directly supported by the document that matches the question’s framing (e.g., the doc that identifies the person in the referenced role).\n",
            "   - Most specific (e.g., includes full names or exact phrasing).\n",
            "6) If the answer is not stated anywhere in the provided context, respond with: Not specified in the provided context.\n",
            "7) Output formatting: a single line containing only the answer string.\n",
            "\n",
            "Process to follow:\n",
            "- Parse the question to identify the target entity and the attribute asked.\n",
            "- Locate the document(s) that mention both or clearly link the attribute to the entity.\n",
            "- Extract the exact answer text, following the precision and formatting rules above.\n",
            "- Output only that exact answer.\n",
            "2025/11/06 17:38:54 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
            "2025/11/06 17:38:54 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score 2 is better than old score 1. Continue to full eval and add to candidate pool.\n",
            "2025/11/06 17:39:05 INFO dspy.evaluate.evaluate: Average Metric: 28.0 / 50 (56.0%)\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.56\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.56\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.6\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {1}, {0}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {1}, {1}]\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.56\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.56\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.56\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
            "GEPA Optimization:  71%|███████   | 106/150 [01:05<00:30,  1.44rollouts/s]2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 2: No merge candidates found\n",
            "2025/11/06 17:39:05 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 1 score: 0.56\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:02<00:00,  1.03it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:39:08 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:40:20 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for predict: Task: Answer a single question using only the provided “context” documents. Return a concise, exact answer string with no extra text.\n",
            "\n",
            "Core rules:\n",
            "1) Use only information explicitly stated in the provided context. Do not use outside knowledge or infer beyond what is written.\n",
            "2) Identify the target entity and the attribute asked in the question, then locate the document(s) that mention both or clearly link them.\n",
            "3) Prefer the source that explicitly ties the attribute to the entity as framed by the question. Cross-reference other documents only when necessary and only to the extent allowed below.\n",
            "\n",
            "Answer precision:\n",
            "4) Return the answer in the most precise, fully specified form that is supported by the context AND consistent with the source that ties the attribute to the entity.\n",
            "   - Names: Preserve the exact spelling, capitalization, diacritics, hyphens, and stylization. Include middle names only if:\n",
            "     a) the same document that ties the attribute to the entity provides the fuller name, or\n",
            "     b) the question contains descriptors that uniquely match a different document providing the fuller name, and it is unambiguously the same person.\n",
            "     Otherwise, use the exact name form in the document that ties the attribute to the entity.\n",
            "   - Ages: Match the exact phrasing (e.g., “16-year-old”).\n",
            "   - Years: Return only the 4-digit year unless the question asks for more detail.\n",
            "   - Titles, events, and stylization: Preserve exact forms (e.g., “Super Bowl XLVIII”).\n",
            "\n",
            "Disambiguation and selection:\n",
            "5) If multiple candidates exist, choose the one:\n",
            "   - Most directly supported by the document that matches the question’s framing (e.g., the film page listing the star for “Who starred in …”).\n",
            "   - Most specific while remaining consistent with that directly supporting document.\n",
            "6) Use qualifiers in the question to disambiguate (e.g., “male actor,” “American actor,” specific role, year).\n",
            "7) Do not import extra details (e.g., middle names) from a different document unless allowed by rule 4. For example: if the film document lists “Robert Sheehan” as a star and a separate bio lists “Robert Michael Sheehan,” answer “Robert Sheehan” because the film document is the one tying the attribute (starring) to the entity. Conversely, if the question includes descriptive clauses that uniquely identify a person (e.g., “American stage, film, and television actor who also appeared in a large number of musicals”) and another document with that descriptor provides a fuller name while a second document confirms the specific role, you may use the fuller name as the answer.\n",
            "\n",
            "If not found:\n",
            "8) If the answer is not stated anywhere in the provided context, respond with: Not specified in the provided context.\n",
            "\n",
            "Output format:\n",
            "9) Output a single line containing only the answer string. Do not include any extra words, explanations, reasoning, or punctuation beyond what appears in the answer itself.\n",
            "\n",
            "Process checklist:\n",
            "- Parse the question to extract the entity and attribute.\n",
            "- Find the document that explicitly ties the attribute to the entity.\n",
            "- Use qualifiers in the question to select the correct entry if multiple are listed.\n",
            "- If needed, cross-reference only to confirm identity or to use a fuller name per rule 4.\n",
            "- Extract the exact answer text, preserving original stylization.\n",
            "- Output only that exact answer on one line.\n",
            "2025/11/06 17:40:23 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
            "2025/11/06 17:40:23 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score 3 is better than old score 2. Continue to full eval and add to candidate pool.\n",
            "2025/11/06 17:40:31 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 50 (58.0%)\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program is on the linear pareto front\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset score for new program: 0.58\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full train_val score for new program: 0.58\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Individual valset scores for new program: [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New valset pareto front scores: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset pareto front score: 0.62\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Updated valset pareto front programs: [{1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0}, {1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {1, 2}, {1, 2}, {0, 1, 2}, {1, 2}, {1}]\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best valset aggregate score so far: 0.58\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on train_val: 2\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on valset: 2\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on valset: 0.58\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on train_val: 0.58\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Linear pareto front program index: 2\n",
            "2025/11/06 17:40:31 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program candidate index: 2\n",
            "GEPA Optimization:  71%|███████   | 106/150 [02:31<01:02,  1.43s/rollouts]\n"
          ]
        }
      ],
      "source": [
        "# Run GEPA optimization with DEFAULT proposer (single LLM) for comparison\n",
        "optimizer_default = GEPA(\n",
        "    metric=metric_with_feedback,\n",
        "    reflection_lm=dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000),  # Single LLM for proposals\n",
        "    max_full_evals=1,\n",
        "    num_threads=32,\n",
        "    track_stats=True,\n",
        "    reflection_minibatch_size=3,\n",
        ")\n",
        "\n",
        "print(\"Starting GEPA optimization with DEFAULT proposer for comparison...\")\n",
        "optimized_program_default = optimizer_default.compile(\n",
        "    program,\n",
        "    trainset=train_set,\n",
        "    valset=val_set,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating default optimized program on test set...\n",
            "Average Metric: 63.00 / 100 (63.0%): 100%|██████████| 100/100 [00:11<00:00,  8.50it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/11/06 17:43:10 INFO dspy.evaluate.evaluate: Average Metric: 63 / 100 (63.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>example_answer</th>\n",
              "      <th>reasoning</th>\n",
              "      <th>pred_answer</th>\n",
              "      <th>&lt;lambda&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Document 1: Ed Wood (film) Ed Wood is a 1994 American biographical...</td>\n",
              "      <td>Were Scott Derrickson and Ed Wood of the same nationality?</td>\n",
              "      <td>yes</td>\n",
              "      <td>Scott Derrickson is described as an American director, screenwrite...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Document 1: Meet Corliss Archer Meet Corliss Archer, a program fro...</td>\n",
              "      <td>What government position was held by the woman who portrayed Corli...</td>\n",
              "      <td>Chief of Protocol</td>\n",
              "      <td>The question asks for the government position held by the woman wh...</td>\n",
              "      <td>United States ambassador to Ghana</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Document 1: Andre Norton Award The Andre Norton Award for Young Ad...</td>\n",
              "      <td>What science fantasy young adult series, told in first person, has...</td>\n",
              "      <td>Animorphs</td>\n",
              "      <td>The question asks for a science fantasy young adult series, told i...</td>\n",
              "      <td>Animorphs</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Document 1: Esma Sultan (daughter of Abdülaziz) Esma Sultan (21 Ma...</td>\n",
              "      <td>Are the Laleli Mosque and Esma Sultan Mansion located in the same ...</td>\n",
              "      <td>no</td>\n",
              "      <td>Document 6 states that the Laleli Mosque is located in Laleli, Fat...</td>\n",
              "      <td>No</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Document 1: Just Another Romantic Wrestling Comedy Just Another Ro...</td>\n",
              "      <td>The director of the romantic comedy \"Big Stone Gap\" is based in wh...</td>\n",
              "      <td>Greenwich Village, New York City</td>\n",
              "      <td>Document 10 states that \"Big Stone Gap\" (2014 film) was written an...</td>\n",
              "      <td>Greenwich Village, New York City</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Document 1: Scott's Run Nature Preserve Scott's Run Nature Preserv...</td>\n",
              "      <td>Tysons Galleria is located in what county?</td>\n",
              "      <td>Fairfax County</td>\n",
              "      <td>Document 2 states that Tysons Galleria is located in McLean, Virgi...</td>\n",
              "      <td>Fairfax County</td>\n",
              "      <td>✔️ [1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Document 1: Cardinal Health Cardinal Health, Inc. is a Fortune 500...</td>\n",
              "      <td>Bordan Tkachuk was the CEO of a company that provides what sort of...</td>\n",
              "      <td>IT products and services</td>\n",
              "      <td>The question asks what sort of products were provided by the compa...</td>\n",
              "      <td>IT products and services, including storage systems, servers, work...</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Document 1: Aryanto Yuniawan Aryanto Yuniawan (born June 18, 1977 ...</td>\n",
              "      <td>Which filmmaker was known for animation, Lev Yilmaz or Pamela B. G...</td>\n",
              "      <td>Levni Yilmaz</td>\n",
              "      <td>The context indicates that Lev Yilmaz is a San Francisco based ind...</td>\n",
              "      <td>Lev Yilmaz</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Document 1: Visa policy of Hong Kong The visa policy of Hong Kong ...</td>\n",
              "      <td>In which city is the ambassador of the Rabat-Salé-Kénitra administ...</td>\n",
              "      <td>Beijing</td>\n",
              "      <td>The Rabat-Salé-Kénitra administrative region is mentioned in Docum...</td>\n",
              "      <td>Rabat</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Document 1: Fuding Railway Station Fuding Railway Station () is a ...</td>\n",
              "      <td>Are Yingkou and Fuding the same level of city?</td>\n",
              "      <td>no</td>\n",
              "      <td>According to Document 2, Yingkou is a prefecture-level city in Lia...</td>\n",
              "      <td>No, Yingkou is a prefecture-level city while Fuding is a county-le...</td>\n",
              "      <td>✔️ [0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  context  \\\n",
              "0   Document 1: Ed Wood (film) Ed Wood is a 1994 American biographical...   \n",
              "1   Document 1: Meet Corliss Archer Meet Corliss Archer, a program fro...   \n",
              "2   Document 1: Andre Norton Award The Andre Norton Award for Young Ad...   \n",
              "3   Document 1: Esma Sultan (daughter of Abdülaziz) Esma Sultan (21 Ma...   \n",
              "4   Document 1: Just Another Romantic Wrestling Comedy Just Another Ro...   \n",
              "..                                                                    ...   \n",
              "95  Document 1: Scott's Run Nature Preserve Scott's Run Nature Preserv...   \n",
              "96  Document 1: Cardinal Health Cardinal Health, Inc. is a Fortune 500...   \n",
              "97  Document 1: Aryanto Yuniawan Aryanto Yuniawan (born June 18, 1977 ...   \n",
              "98  Document 1: Visa policy of Hong Kong The visa policy of Hong Kong ...   \n",
              "99  Document 1: Fuding Railway Station Fuding Railway Station () is a ...   \n",
              "\n",
              "                                                                 question  \\\n",
              "0              Were Scott Derrickson and Ed Wood of the same nationality?   \n",
              "1   What government position was held by the woman who portrayed Corli...   \n",
              "2   What science fantasy young adult series, told in first person, has...   \n",
              "3   Are the Laleli Mosque and Esma Sultan Mansion located in the same ...   \n",
              "4   The director of the romantic comedy \"Big Stone Gap\" is based in wh...   \n",
              "..                                                                    ...   \n",
              "95                             Tysons Galleria is located in what county?   \n",
              "96  Bordan Tkachuk was the CEO of a company that provides what sort of...   \n",
              "97  Which filmmaker was known for animation, Lev Yilmaz or Pamela B. G...   \n",
              "98  In which city is the ambassador of the Rabat-Salé-Kénitra administ...   \n",
              "99                         Are Yingkou and Fuding the same level of city?   \n",
              "\n",
              "                      example_answer  \\\n",
              "0                                yes   \n",
              "1                  Chief of Protocol   \n",
              "2                          Animorphs   \n",
              "3                                 no   \n",
              "4   Greenwich Village, New York City   \n",
              "..                               ...   \n",
              "95                    Fairfax County   \n",
              "96          IT products and services   \n",
              "97                      Levni Yilmaz   \n",
              "98                           Beijing   \n",
              "99                                no   \n",
              "\n",
              "                                                                reasoning  \\\n",
              "0   Scott Derrickson is described as an American director, screenwrite...   \n",
              "1   The question asks for the government position held by the woman wh...   \n",
              "2   The question asks for a science fantasy young adult series, told i...   \n",
              "3   Document 6 states that the Laleli Mosque is located in Laleli, Fat...   \n",
              "4   Document 10 states that \"Big Stone Gap\" (2014 film) was written an...   \n",
              "..                                                                    ...   \n",
              "95  Document 2 states that Tysons Galleria is located in McLean, Virgi...   \n",
              "96  The question asks what sort of products were provided by the compa...   \n",
              "97  The context indicates that Lev Yilmaz is a San Francisco based ind...   \n",
              "98  The Rabat-Salé-Kénitra administrative region is mentioned in Docum...   \n",
              "99  According to Document 2, Yingkou is a prefecture-level city in Lia...   \n",
              "\n",
              "                                                              pred_answer  \\\n",
              "0                                                                     Yes   \n",
              "1                                       United States ambassador to Ghana   \n",
              "2                                                               Animorphs   \n",
              "3                                                                      No   \n",
              "4                                        Greenwich Village, New York City   \n",
              "..                                                                    ...   \n",
              "95                                                         Fairfax County   \n",
              "96  IT products and services, including storage systems, servers, work...   \n",
              "97                                                             Lev Yilmaz   \n",
              "98                                                                  Rabat   \n",
              "99  No, Yingkou is a prefecture-level city while Fuding is a county-le...   \n",
              "\n",
              "   <lambda>  \n",
              "0    ✔️ [1]  \n",
              "1    ✔️ [0]  \n",
              "2    ✔️ [1]  \n",
              "3    ✔️ [1]  \n",
              "4    ✔️ [1]  \n",
              "..      ...  \n",
              "95   ✔️ [1]  \n",
              "96   ✔️ [0]  \n",
              "97   ✔️ [0]  \n",
              "98   ✔️ [0]  \n",
              "99   ✔️ [0]  \n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final accuracy (default): 63.0%\n",
            "Correct: 63 / 100\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the default optimized program on test set\n",
        "evaluate_default = dspy.Evaluate(\n",
        "    devset=test_set,\n",
        "    metric=lambda example, prediction, trace=None, pred_name=None, pred_trace=None: \n",
        "        int(example['answer'].strip().lower() == prediction.answer.strip().lower()) if hasattr(prediction, 'answer') else 0,\n",
        "    num_threads=32,\n",
        "    display_table=True,\n",
        "    display_progress=True\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluating default optimized program on test set...\")\n",
        "result_default = evaluate_default(optimized_program_default)\n",
        "print(f\"\\nFinal accuracy (default): {result_default.score}%\")\n",
        "print(f\"Correct: {result_default.score * len(test_set) / 100:.0f} / {len(test_set)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINAL COMPARISON: MultiLLMProposalFn vs Default GEPA\n",
            "================================================================================\n",
            "\n",
            "Metric                         MultiLLM                  Default                   Difference     \n",
            "-----------------------------------------------------------------------------------------------\n",
            "Test Accuracy                   65.00%                 62.00%                 +3.00%\n",
            "Correct Answers                  65.0/100                   62.0/100                   +3.0\n",
            "\n",
            "================================================================================\n",
            "✓ MultiLLMProposalFn is BETTER by 3.00 percentage points\n",
            "  Relative improvement: +4.84%\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Final comparison\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL COMPARISON: MultiLLMProposalFn vs Default GEPA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "multi_llm_score = result.score\n",
        "default_score = result_default.score\n",
        "\n",
        "print(f\"\\n{'Metric':<30} {'MultiLLM':<25} {'Default':<25} {'Difference':<15}\")\n",
        "print(\"-\" * 95)\n",
        "print(f\"{'Test Accuracy':<30} {multi_llm_score:>6.2f}%{'':>15} {default_score:>6.2f}%{'':>15} {multi_llm_score - default_score:>+6.2f}%\")\n",
        "print(f\"{'Correct Answers':<30} {multi_llm_score * len(test_set) / 100:>6.1f}/{len(test_set):<4}{'':>15} {default_score * len(test_set) / 100:>6.1f}/{len(test_set):<4}{'':>15} {(multi_llm_score - default_score) * len(test_set) / 100:>+6.1f}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "if multi_llm_score > default_score:\n",
        "    improvement = ((multi_llm_score / default_score) - 1) * 100 if default_score > 0 else 0\n",
        "    print(f\"✓ MultiLLMProposalFn is BETTER by {multi_llm_score - default_score:.2f} percentage points\")\n",
        "    print(f\"  Relative improvement: {improvement:+.2f}%\")\n",
        "elif default_score > multi_llm_score:\n",
        "    improvement = ((default_score / multi_llm_score) - 1) * 100 if multi_llm_score > 0 else 0\n",
        "    print(f\"✓ Default GEPA is BETTER by {default_score - multi_llm_score:.2f} percentage points\")\n",
        "    print(f\"  Relative improvement: {improvement:+.2f}%\")\n",
        "else:\n",
        "    print(\"Both approaches perform equally well\")\n",
        "print(f\"{'='*80}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gepa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
