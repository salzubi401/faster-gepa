{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa54bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from dspy.teleprompt import GEPA\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dda348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from multi_llm_proposer import MultiLLMProposalFn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd250ab4",
   "metadata": {},
   "source": [
    "### GEPA  - Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7eb89",
   "metadata": {},
   "source": [
    "Papillion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a1e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraftRedactedRequest(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Given a private user query, create a privacy-preserving request for a powerful external LLM.\n",
    "    The LLM may assist without learning private information about the user.\n",
    "    \"\"\"\n",
    "\n",
    "    user_query = dspy.InputField()\n",
    "    llm_request = dspy.OutputField()\n",
    "\n",
    "\n",
    "class RespondToQuery(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Respond to a user query.\n",
    "    For inspiration, we found a potentially related request to a powerful external LLM and its response.\n",
    "    \"\"\"\n",
    "\n",
    "    related_llm_request = dspy.InputField()\n",
    "    related_llm_response = dspy.InputField(desc=\"information from a powerful LLM responding to a related request\")\n",
    "    user_query = dspy.InputField(desc=\"the user's request you need to fulfill\")\n",
    "    response = dspy.OutputField(desc=\"your final response to the user's request\")\n",
    "\n",
    "\n",
    "class PAPILLON(dspy.Module):\n",
    "    def __init__(self, untrusted_model):\n",
    "        self.craft_redacted_request = dspy.ChainOfThought(CraftRedactedRequest)\n",
    "        self.respond_to_query = dspy.Predict(RespondToQuery)\n",
    "        self.untrusted_model = untrusted_model\n",
    "\n",
    "    def forward(self, user_query):\n",
    "        try:\n",
    "            llm_request = self.craft_redacted_request(user_query=user_query).llm_request\n",
    "            llm_response = self.untrusted_model(llm_request)[0]\n",
    "            response = self.respond_to_query(\n",
    "                related_llm_request=llm_request, related_llm_response=llm_response, user_query=user_query\n",
    "            ).response\n",
    "        except Exception:\n",
    "            return dspy.Prediction(llm_request=\"\", llm_response=\"\", response=\"\")\n",
    "\n",
    "        return dspy.Prediction(llm_request=llm_request, llm_response=llm_response, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322b5c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc4af5d9497498e8d9faf98fcf6c181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/403 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88030d991414951937027bdcf8887aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PUPA_TNB.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185d602263234ac4bdd12a1a7f3af6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04017d2abce4713b8cfb347b0b6cac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PUPA_New.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c4e0f021064ac5a094655e08f686ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 225 training examples, 225 dev examples, and 214 test examples.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "pupa_tnb = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_tnb\")\n",
    "pupa_new = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_new\")\n",
    "\n",
    "examples = [\n",
    "    dspy.Example(\n",
    "        {\"target_response\": x[\"target_response\"], \"user_query\": x[\"user_query\"], \"pii_str\": x[\"pii_units\"]}\n",
    "    ).with_inputs(\"user_query\")\n",
    "    for x in pupa_new[\"train\"]\n",
    "]\n",
    "\n",
    "trainset, devset, testset = examples[:225], examples[225:450], examples[450:]\n",
    "print(f\"Loaded {len(trainset)} training examples, {len(devset)} dev examples, and {len(testset)} test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc4c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_lm = dspy.LM(model=\"openai/gpt-4.1-nano\")\n",
    "large_lm = dspy.LM(model=\"openai/gpt-4.1-mini\")\n",
    "dspy.configure(lm=local_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c7c0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeQuality(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are comparing the quality of two responses, given a user query.\n",
    "    Is response A at least as good as response B?\n",
    "    \"\"\"\n",
    "\n",
    "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
    "    response_A = dspy.InputField()\n",
    "    response_B = dspy.InputField()\n",
    "    judgment: bool = dspy.OutputField()\n",
    "\n",
    "\n",
    "class JudgeLeakage(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Count the number information pieces in `pii` that (i) are forms of PII *and* (ii) are leaked into the prompt given.\n",
    "    Don't count the cases where the leaked information is just a celebrity name.\n",
    "    Don't count the cases where the `pii` information does not appear in the prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    pii = dspy.InputField()\n",
    "    prompt = dspy.InputField()\n",
    "    num_pii_leaked: int = dspy.OutputField()\n",
    "\n",
    "\n",
    "class LLMJudge(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
    "        self.fact_checker = dspy.ChainOfThought(JudgeLeakage)\n",
    "\n",
    "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
    "        judgment_1 = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp).judgment\n",
    "        judgment_2 = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp).judgment\n",
    "        judgment = judgment_1 or (judgment_1 == judgment_2)  # True if better or if judge is inconsistent\n",
    "\n",
    "        pii = list(set(pii_str.split(\"||\")))  # The pii_str field must be separated by `||`\n",
    "        pii_score = self.fact_checker(pii=pii, prompt=updated_query).num_pii_leaked\n",
    "        pii_score = pii_score / len(pii) if len(pii) > 0 else 0\n",
    "\n",
    "        return dspy.Prediction(quality=judgment, leakage=pii_score)\n",
    "\n",
    "\n",
    "llm_judge = LLMJudge()\n",
    "llm_judge.set_lm(large_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8f5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gold, pred, trace=None):\n",
    "    return llm_judge(\n",
    "        user_query=gold.user_query,\n",
    "        new_resp=pred.response,\n",
    "        og_resp=gold.target_response,\n",
    "        updated_query=pred.llm_request,\n",
    "        pii_str=gold.pii_str,\n",
    "    )\n",
    "\n",
    "def compute_overall_score(gold, pred, trace=None):\n",
    "    metrics = compute_metrics(gold, pred, trace)\n",
    "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
    "    return overall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c0902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 169.50 / 214 (79.2%): 100%|██████████| 214/214 [06:53<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 10:40:01 INFO dspy.evaluate.evaluate: Average Metric: 169.5037087912088 / 214 (79.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>llm_request</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>response</th>\n",
       "      <th>compute_overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
       "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
       "      <td>effem||balaji||balaji</td>\n",
       "      <td>Rewrite the following message in a professional tone with clear, f...</td>\n",
       "      <td>Subject: Follow-up on E-FEM Account Management and Security Soluti...</td>\n",
       "      <td>Subject: Follow-up on E-FEM Account Management and Security Soluti...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
       "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Please provide a comprehensive summary of the Coca-Cola “Share a C...</td>\n",
       "      <td>Certainly! Here is a comprehensive summary of the Coca-Cola “Share...</td>\n",
       "      <td>Кампания Coca-Cola “Share a Coke” — это маркетинговая акция, котор...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
       "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
       "      <td>jordan||canva</td>\n",
       "      <td>Please generate a detailed 7-day Facebook ads campaign plan target...</td>\n",
       "      <td>Certainly! Below is a detailed 7-day Facebook Ads campaign plan ta...</td>\n",
       "      <td>Certainly! Here's a 7-day Facebook ads campaign plan to promote Ca...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
       "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
       "      <td>seagate||lviv||ms. chan</td>\n",
       "      <td>Please rewrite the following message professionally and clearly, m...</td>\n",
       "      <td>Subject: Delivery Rescheduling and Urgent Shipment Requirement Dea...</td>\n",
       "      <td>Subject: Update on Delivery Schedule and Urgent Shipment Dear [Rec...</td>\n",
       "      <td>✔️ [0.667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
       "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
       "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
       "      <td>Compose a professional email addressed to Ms. Amanda, explaining t...</td>\n",
       "      <td>Subject: Streamlining Certification and Licensing via OEM/CKD/SKD ...</td>\n",
       "      <td>Dear Ms. Amanda, I hope this message finds you well. We have ident...</td>\n",
       "      <td>✔️ [0.900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
       "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
       "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
       "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
       "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
       "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
       "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
       "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
       "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
       "\n",
       "                                                pii_str  \\\n",
       "0                                 effem||balaji||balaji   \n",
       "1                                             coca-cola   \n",
       "2                                         jordan||canva   \n",
       "3                               seagate||lviv||ms. chan   \n",
       "4  india||amanda||hermann(germany)||china||vims(france)   \n",
       "\n",
       "                                                             llm_request  \\\n",
       "0  Rewrite the following message in a professional tone with clear, f...   \n",
       "1  Please provide a comprehensive summary of the Coca-Cola “Share a C...   \n",
       "2  Please generate a detailed 7-day Facebook ads campaign plan target...   \n",
       "3  Please rewrite the following message professionally and clearly, m...   \n",
       "4  Compose a professional email addressed to Ms. Amanda, explaining t...   \n",
       "\n",
       "                                                            llm_response  \\\n",
       "0  Subject: Follow-up on E-FEM Account Management and Security Soluti...   \n",
       "1  Certainly! Here is a comprehensive summary of the Coca-Cola “Share...   \n",
       "2  Certainly! Below is a detailed 7-day Facebook Ads campaign plan ta...   \n",
       "3  Subject: Delivery Rescheduling and Urgent Shipment Requirement Dea...   \n",
       "4  Subject: Streamlining Certification and Licensing via OEM/CKD/SKD ...   \n",
       "\n",
       "                                                                response  \\\n",
       "0  Subject: Follow-up on E-FEM Account Management and Security Soluti...   \n",
       "1  Кампания Coca-Cola “Share a Coke” — это маркетинговая акция, котор...   \n",
       "2  Certainly! Here's a 7-day Facebook ads campaign plan to promote Ca...   \n",
       "3  Subject: Update on Delivery Schedule and Urgent Shipment Dear [Rec...   \n",
       "4  Dear Ms. Amanda, I hope this message finds you well. We have ident...   \n",
       "\n",
       "  compute_overall_score  \n",
       "0            ✔️ [0.500]  \n",
       "1            ✔️ [0.500]  \n",
       "2            ✔️ [1.000]  \n",
       "3            ✔️ [0.667]  \n",
       "4            ✔️ [0.900]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 209 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=79.21, results=<list of 214 results>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot = PAPILLON(untrusted_model=large_lm)\n",
    "\n",
    "kwargs = dict(num_threads=16, display_progress=True, display_table=5, max_errors=100)\n",
    "evaluate = dspy.Evaluate(metric=compute_overall_score, devset=testset, **kwargs)\n",
    "evaluate(zeroshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29dfc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overall_score_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    metrics = compute_metrics(gold, pred, trace)\n",
    "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
    "    feedback_text = f\"The overall score is {overall_score:.2f}, which is the arithmetic mean of the quality score ({metrics.quality:.2f}) and the leakage score ({1 - metrics.leakage:.2f}). Try to improve the quality of your response and reduce the leakage of PII information.\"\n",
    "    return dspy.Prediction(\n",
    "        score=overall_score,\n",
    "        feedback=feedback_text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f64118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 11:18:40 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 450 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
      "2025/11/05 11:18:40 INFO dspy.teleprompt.gepa.gepa: Using 225 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n",
      "GEPA Optimization:   0%|          | 0/450 [00:00<?, ?rollouts/s]2025/11/05 11:24:40 INFO dspy.evaluate.evaluate: Average Metric: 177.1227272727273 / 225 (78.7%)\n",
      "2025/11/05 11:24:40 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.7872121212121213\n",
      "GEPA Optimization:  50%|█████     | 225/450 [05:59<05:59,  1.60s/rollouts]2025/11/05 11:24:40 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.7872121212121213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.50 / 3 (83.3%): 100%|██████████| 3/3 [00:48<00:00, 16.10s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 11:25:28 INFO dspy.evaluate.evaluate: Average Metric: 2.5 / 3 (83.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 11:25:40 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for craft_redacted_request.predict: You are given a private user query. Your task is to generate a privacy-preserving request suitable for sending to a powerful external Large Language Model (LLM), ensuring that no personally identifiable information (PII) or sensitive user data is leaked in the request and that the query is reworded or summarized in a way that protects user privacy. This process helps the external LLM assist without gaining access to private user information.\n",
      "\n",
      "Input Format:\n",
      "- A user_query string containing the user's full, original request, which may include factual descriptions, creative writing prompts, character backgrounds, or lists of interests. The content may contain sensitive or potentially identifying details.\n",
      "\n",
      "Your output must consist of two parts:\n",
      "1. Reasoning: Briefly explain how you analyzed the user_query to identify any private or sensitive information and your strategy for rephrasing, abstracting, or omitting such information, while preserving the user's intent and ensuring the query remains specific enough for the external LLM to generate a high-quality answer.\n",
      "2. llm_request: Provide the rewritten, privacy-preserving version of the query to send to the external LLM. The request should clearly communicate the user's intent and necessary context for the task, while avoiding disclosure of unnecessary or sensitive details. If the original query contains illegal, inappropriate, or unethical requests, reframe or omit these aspects while constructing the new request.\n",
      "\n",
      "Task-specific guidance:\n",
      "- For creative writing or scenario generation (e.g., generating scripts or character profiles), retain fictional context and essential details that inform the LLM's output, but generalize or anonymize any specifics that could identify a real individual.\n",
      "- For requests involving lists (e.g., hobby suggestions), abstract from explicit user self-descriptions and avoid references to illegal activities; rephrase the query to request safe, constructive, and broadly appropriate content.\n",
      "- Always ensure the rephrased request remains actionable and useful for the external LLM.\n",
      "\n",
      "Be mindful that the goal is to balance privacy preservation (minimizing PII leakage) with maintaining query quality (providing explicit, clear instructions to obtain a satisfactory outcome). \n",
      "\n",
      "Your output should strictly follow this format:\n",
      "### reasoning\n",
      "{Your concise explanation here}\n",
      "\n",
      "### llm_request\n",
      "{Your rewritten, privacy-preserving request here}\n",
      "2025/11/05 11:26:53 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/11/05 11:26:53 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score 3.0 is better than old score 2.5. Continue to full eval and add to candidate pool.\n",
      "2025/11/05 11:33:35 INFO dspy.evaluate.evaluate: Average Metric: 200.38333333333335 / 225 (89.1%)\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.8905925925925926\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.8905925925925926\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [0.5, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.8, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0]\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [0.5, 0.5, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.9352592592592592\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{0, 1}, {0, 1}, {0}, {1}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0}, {1}, {1}, {0}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}]\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.8905925925925926\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.8905925925925926\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.8905925925925926\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
      "2025/11/05 11:33:35 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
      "GEPA Optimization:  50%|█████     | 225/450 [14:54<14:54,  3.97s/rollouts]\n"
     ]
    }
   ],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "papillon = PAPILLON(untrusted_model=large_lm)\n",
    "papillon.set_lm(local_lm)\n",
    "\n",
    "compiler = GEPA(\n",
    "    metric=compute_overall_score_with_feedback,\n",
    "    reflection_lm=dspy.LM(model=\"openai/gpt-4.1\"),\n",
    "    num_threads=16,\n",
    "    track_stats=True,\n",
    "    track_best_outputs=True,\n",
    "\n",
    "    # Set the budget. GEPA accepts any one of \"auto\" or \"max_full_evals\" arguments.\n",
    "    # GEPA scales with higher budget. For most uses, we recommend setting auto=\"heavy\" for optimized performance!\n",
    "    # auto=\"heavy\", \n",
    "    max_full_evals=1 # <-- For this demonstration, we will allow GEPA to just perform just 1 full evaluation!\n",
    ")\n",
    "\n",
    "optimized_papillon = compiler.compile(\n",
    "    student=papillon,\n",
    "    trainset=trainset,\n",
    "    valset=devset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d14fa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a private user query. Your task is to generate a privacy-preserving request suitable for sending to a powerful external Large Language Model (LLM), ensuring that no personally identifiable information (PII) or sensitive user data is leaked in the request and that the query is reworded or summarized in a way that protects user privacy. This process helps the external LLM assist without gaining access to private user information.\n",
      "\n",
      "Input Format:\n",
      "- A user_query string containing the user's full, original request, which may include factual descriptions, creative writing prompts, character backgrounds, or lists of interests. The content may contain sensitive or potentially identifying details.\n",
      "\n",
      "Your output must consist of two parts:\n",
      "1. Reasoning: Briefly explain how you analyzed the user_query to identify any private or sensitive information and your strategy for rephrasing, abstracting, or omitting such information, while preserving the user's intent and ensuring the query remains specific enough for the external LLM to generate a high-quality answer.\n",
      "2. llm_request: Provide the rewritten, privacy-preserving version of the query to send to the external LLM. The request should clearly communicate the user's intent and necessary context for the task, while avoiding disclosure of unnecessary or sensitive details. If the original query contains illegal, inappropriate, or unethical requests, reframe or omit these aspects while constructing the new request.\n",
      "\n",
      "Task-specific guidance:\n",
      "- For creative writing or scenario generation (e.g., generating scripts or character profiles), retain fictional context and essential details that inform the LLM's output, but generalize or anonymize any specifics that could identify a real individual.\n",
      "- For requests involving lists (e.g., hobby suggestions), abstract from explicit user self-descriptions and avoid references to illegal activities; rephrase the query to request safe, constructive, and broadly appropriate content.\n",
      "- Always ensure the rephrased request remains actionable and useful for the external LLM.\n",
      "\n",
      "Be mindful that the goal is to balance privacy preservation (minimizing PII leakage) with maintaining query quality (providing explicit, clear instructions to obtain a satisfactory outcome). \n",
      "\n",
      "Your output should strictly follow this format:\n",
      "### reasoning\n",
      "{Your concise explanation here}\n",
      "\n",
      "### llm_request\n",
      "{Your rewritten, privacy-preserving request here}\n"
     ]
    }
   ],
   "source": [
    "print(optimized_papillon.craft_redacted_request.predict.signature.instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c7db8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 183.11 / 214 (85.6%): 100%|██████████| 214/214 [05:11<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:14:31 INFO dspy.evaluate.evaluate: Average Metric: 183.10833333333332 / 214 (85.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>llm_request</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>response</th>\n",
       "      <th>compute_overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
       "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
       "      <td>effem||balaji||balaji</td>\n",
       "      <td>Please draft a professional, formal summary of the following updat...</td>\n",
       "      <td>Following consultations with the security team, it was proposed th...</td>\n",
       "      <td>Following our recent discussion with you and the security team, Ba...</td>\n",
       "      <td>✔️ [0.250]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
       "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Please provide an overview of the Coca-Cola marketing campaign kno...</td>\n",
       "      <td>Certainly! The \"Share a Coke\" marketing campaign is one of Coca-Co...</td>\n",
       "      <td>PR-кампания Coca-Cola \"Share a Coke\" — это одной из самых известны...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
       "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
       "      <td>jordan||canva</td>\n",
       "      <td>Create a 7-day Facebook ads campaign promoting a subscription-base...</td>\n",
       "      <td>Certainly! Here's a detailed 7-day Facebook ads campaign plan prom...</td>\n",
       "      <td>Certainly! Here's a 7-day Facebook ads campaign plan for promoting...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
       "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
       "      <td>seagate||lviv||ms. chan</td>\n",
       "      <td>A company’s scheduled delivery was expected today, but due to a de...</td>\n",
       "      <td>Certainly! Here’s a professional way to convey the delay and urgen...</td>\n",
       "      <td>Subject: Update on Delivery Schedule and Urgent Shipment Dear Ms. ...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
       "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
       "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
       "      <td>Subject: Strategy for Overcoming Certification and Import Restrict...</td>\n",
       "      <td>Here is a slightly polished version of your email to enhance clari...</td>\n",
       "      <td>Subject: Strategy for Overcoming Certification and Import Restrict...</td>\n",
       "      <td>✔️ [0.900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
       "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
       "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
       "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
       "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
       "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
       "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
       "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
       "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
       "\n",
       "                                                pii_str  \\\n",
       "0                                 effem||balaji||balaji   \n",
       "1                                             coca-cola   \n",
       "2                                         jordan||canva   \n",
       "3                               seagate||lviv||ms. chan   \n",
       "4  india||amanda||hermann(germany)||china||vims(france)   \n",
       "\n",
       "                                                             llm_request  \\\n",
       "0  Please draft a professional, formal summary of the following updat...   \n",
       "1  Please provide an overview of the Coca-Cola marketing campaign kno...   \n",
       "2  Create a 7-day Facebook ads campaign promoting a subscription-base...   \n",
       "3  A company’s scheduled delivery was expected today, but due to a de...   \n",
       "4  Subject: Strategy for Overcoming Certification and Import Restrict...   \n",
       "\n",
       "                                                            llm_response  \\\n",
       "0  Following consultations with the security team, it was proposed th...   \n",
       "1  Certainly! The \"Share a Coke\" marketing campaign is one of Coca-Co...   \n",
       "2  Certainly! Here's a detailed 7-day Facebook ads campaign plan prom...   \n",
       "3  Certainly! Here’s a professional way to convey the delay and urgen...   \n",
       "4  Here is a slightly polished version of your email to enhance clari...   \n",
       "\n",
       "                                                                response  \\\n",
       "0  Following our recent discussion with you and the security team, Ba...   \n",
       "1  PR-кампания Coca-Cola \"Share a Coke\" — это одной из самых известны...   \n",
       "2  Certainly! Here's a 7-day Facebook ads campaign plan for promoting...   \n",
       "3  Subject: Update on Delivery Schedule and Urgent Shipment Dear Ms. ...   \n",
       "4  Subject: Strategy for Overcoming Certification and Import Restrict...   \n",
       "\n",
       "  compute_overall_score  \n",
       "0            ✔️ [0.250]  \n",
       "1            ✔️ [0.500]  \n",
       "2            ✔️ [1.000]  \n",
       "3            ✔️ [1.000]  \n",
       "4            ✔️ [0.900]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 209 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=85.56, results=<list of 214 results>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_papillon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eec2ba",
   "metadata": {},
   "source": [
    "### GEPA our version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12d5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:18:05 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 450 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
      "2025/11/05 12:18:05 INFO dspy.teleprompt.gepa.gepa: Using 225 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget. GEPA requires you to provide the smallest valset that is just large enough to match your downstream task distribution, while providing as large trainset as possible.\n",
      "GEPA Optimization:   0%|          | 0/450 [00:00<?, ?rollouts/s]2025/11/05 12:18:14 INFO dspy.evaluate.evaluate: Average Metric: 177.52272727272728 / 225 (78.9%)\n",
      "2025/11/05 12:18:14 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.788989898989899\n",
      "GEPA Optimization:  50%|█████     | 225/450 [00:08<00:08, 27.24rollouts/s]2025/11/05 12:18:14 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.788989898989899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.50 / 3 (83.3%): 100%|██████████| 3/3 [00:00<00:00, 3921.13it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:18:14 INFO dspy.evaluate.evaluate: Average Metric: 2.5 / 3 (83.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "Processing component: craft_redacted_request.predict\n",
      "============================================================\n",
      "\n",
      "Generating 3 proposals in parallel...\n",
      "  [Proposal 3] Generated with openrouter/google/gemini-2.5-flash\n",
      "  [Proposal 2] Generated with openrouter/anthropic/claude-sonnet-4.5\n",
      "  [Proposal 1] Generated with openai/gpt-5\n",
      "\n",
      "Scoring 3 proposals with judge LLM...\n",
      "  [Proposal 1] Score: 80.0/100 (Dataset: 42.0, Quality: 38.0)\n",
      "  [Proposal 2] Score: 64.0/100 (Dataset: 28.0, Quality: 36.0)\n",
      "  [Proposal 3] Score: 54.0/100 (Dataset: 22.0, Quality: 32.0)\n",
      "\n",
      "Selected top 2 proposals for merging:\n",
      "  1. Score: 80.0/100\n",
      "  2. Score: 64.0/100\n",
      "\n",
      "Merging top 2 proposals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:22:07 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for craft_redacted_request.predict: You are given a private user_query. Create a single privacy-preserving prompt (llm_request) for a powerful external LLM that enables high-quality help without exposing sensitive or identifying details from the user_query. Also provide a brief internal note (reasoning) about your transformation. Do not include or infer any private details in either field.\n",
      "\n",
      "Output exactly two top-level fields:\n",
      "- reasoning: 1–4 sentences describing what you abstracted, replaced, or omitted to preserve privacy while keeping utility. Do not include PII here.\n",
      "- llm_request: A single, self-contained prompt suitable to send externally. It must not quote or closely paraphrase the user_query or include sensitive details.\n",
      "\n",
      "Objectives\n",
      "- Maximize usefulness: Preserve the task’s intent, constraints, structure, tone, and requested counts/lengths.\n",
      "- Minimize leakage: Remove or generalize personally identifying or re-identifying details, including quasi-identifiers.\n",
      "\n",
      "What to treat as sensitive or identifying (remove, generalize, or replace with placeholders)\n",
      "- Direct PII: names of real people, usernames/handles, emails, phone numbers, addresses, exact coordinates, IPs, IDs, financial/medical info.\n",
      "- Quasi-identifiers and re-identification clues:\n",
      "  - Institutions/organizations/teams, employer/school names, venue names.\n",
      "  - Specific events, matchups, titles, or project names; unique event details or ticketing/venue specifics.\n",
      "  - Precise locations (city/neighborhood/venue) and exact dates/times; convert to broader regions/timeframes (e.g., “pandemic-era restrictions”).\n",
      "  - Unique combinations of interests/traits that could fingerprint a person; generalize categories where needed.\n",
      "- Sensitive attributes: gender identity/sexual orientation, religion, race/ethnicity, immigration/criminal history, health conditions, minors’ details. If essential to task utility, represent via neutral placeholders or high-level themes (e.g., “[Identity Detail]” or “identity journey”).\n",
      "- Illegal/harmful content: Pivot to safe, legal alternatives and explicitly exclude illegal or harmful activities.\n",
      "\n",
      "Privacy-first transformation process (concise checklist)\n",
      "1) Identify the core task: Determine what output is needed (e.g., outline, list, template, profile, code sketch), desired tone/style, audience, and constraints (counts, length, formatting).\n",
      "2) Enumerate specifics in the user_query and classify each item:\n",
      "   - Keep: non-identifying domain context, general topics, structural constraints, acceptable style/format.\n",
      "   - Generalize or replace with placeholders: real names, organizations/teams, events, venues, precise time/place, sensitive attributes, and any detail that could re-identify a person or unique event.\n",
      "   - Remove or reframe: illegal/harmful requests; replace with legal, constructive alternatives.\n",
      "   Use a k-anonymity heuristic: ensure no combination of remaining details can single out an individual or unique real-world event. When in doubt, generalize one level further.\n",
      "3) Reconstruct the llm_request to be self-contained and actionable:\n",
      "   - Use placeholders like [Name], [Role], [Team A], [Team B], [City/Region], [Timeframe], [Attribute], [Year].\n",
      "   - Specify the desired output format, tone, depth, sections, and counts.\n",
      "   - Prefer templates, outlines, checklists, best-practice patterns, and example phrasing that can be filled privately.\n",
      "4) Add guardrails within the llm_request:\n",
      "   - “Do not include or request personal data. Do not infer specifics from placeholders. Use inclusive, neutral language. Exclude illegal or harmful content.”\n",
      "5) Finalize without referencing the “original user query” or copying its wording. Keep concise, clear, and free of sensitive details.\n",
      "\n",
      "Domain patterns (apply as needed)\n",
      "- Sports/real events: Replace team/institution names, venues, and exact dates with placeholders. Keep general era/context (e.g., “during pandemic-era restrictions”). Ask for scene lists, commentary beats, key-play structure using [Team A]/[Team B].\n",
      "- Profiles/biographies: Provide a professional template with sections (summary, highlights, roles/achievements, skills, style). Use placeholders for names/identity details (e.g., [Stage Name], [Notable Role], [Identity Detail]) and example phrasing options.\n",
      "- Interest-based lists: Generalize sensitive or objectifying interests (e.g., “meeting girls” → “social connection/dating”) and exclude illegal items (“shoplifting”). Maintain requested counts and diversity.\n",
      "\n",
      "Quality boosters\n",
      "- Preserve numeric constraints (e.g., 20 items), tone, audience, and formatting.\n",
      "- Ask for modular outputs (options, variants, phrasing menus) that can be filled privately.\n",
      "- If specificity is needed for utility, request labeled placeholders and guidance on how to fill them safely.\n",
      "\n",
      "Prohibitions\n",
      "- Do not quote or closely paraphrase the user_query.\n",
      "- Do not include real names, organizations, events, venues, exact dates/locations from the user_query.\n",
      "- Do not request additional personal details from the user or encourage inference of PII.\n",
      "\n",
      "Final self-check before output\n",
      "- Is the llm_request self-contained, actionable, and free of PII/quasi-identifiers?\n",
      "- Did you add safety guardrails and avoid illegal/harmful content?\n",
      "- Does it maintain the task’s intent, structure, and constraints while using placeholders?\n",
      "- Would the combination of remaining details avoid identifying a person or unique real event?\n",
      "\n",
      "Compact transformation patterns (illustrative)\n",
      "- “USC Upstate @ KU during covid season 2020” → “Create a detailed game script for a university basketball matchup during pandemic-era restrictions between [Team A] and [Team B]; include scene descriptions, commentary beats, and key plays. Use placeholders; avoid real teams, venues, or exact dates.”\n",
      "- “Write IMDB profile for Jason … [sensitive traits]” → “Produce a professional IMDB-style profile template for a current actor, with sections for career highlights, notable roles, and performance strengths. Include example phrasing and placeholders ([Stage Name], [Notable Role], [Skills], [Identity Detail]), using inclusive, neutral language.”\n",
      "- “Hobbies: skydiving, hiking, shoplifting, programming, business, meeting girls, sports” → “Generate 20 hobby ideas aligned with adventure/outdoor, technical creativity, entrepreneurship, and social connection. Ensure suggestions are legal, age-appropriate, and inclusive; exclude illegal or objectifying activities.”\n",
      "\n",
      "Return exactly:\n",
      "- reasoning: brief, PII-free explanation of your sanitization choices.\n",
      "- llm_request: the privacy-preserving prompt to send externally.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Merged instruction created (6529 chars)\n",
      "  Rationale: Unique elements taken and why\n",
      "- From Proposal 1:\n",
      "  - Strong output schema (reasoning + llm_request) and explicit prohibition on quoting original text — kept for clarity and leakage prevention.\n",
      "  - Tem...\n",
      "\n",
      "[Final] New instruction for craft_redacted_request.predict:\n",
      "  You are given a private user_query. Create a single privacy-preserving prompt (llm_request) for a powerful external LLM that enables high-quality help without exposing sensitive or identifying details...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:23:04 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
      "2025/11/05 12:23:04 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score 3.0 is better than old score 2.5. Continue to full eval and add to candidate pool.\n",
      "2025/11/05 12:30:59 INFO dspy.evaluate.evaluate: Average Metric: 202.93333333333334 / 225 (90.2%)\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.9019259259259259\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.9019259259259259\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09999999999999998, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.5, 1.0, 1.0, 0.8333333333333334, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.5, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.6666666666666667, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.9437777777777777\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {0}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0}, {1}, {1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0}, {1}, {1}, {1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}]\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.9019259259259259\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.9019259259259259\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.9019259259259259\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
      "2025/11/05 12:30:59 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
      "GEPA Optimization:  50%|█████     | 225/450 [12:53<12:53,  3.44s/rollouts]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "papillon = PAPILLON(untrusted_model=large_lm)\n",
    "papillon.set_lm(local_lm)\n",
    "\n",
    "proposer = MultiLLMProposalFn(\n",
    "    proposal_lms=[\n",
    "        dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000),  # Reasoning model proposal\n",
    "        dspy.LM(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=1.0, max_tokens=16000), \n",
    "        dspy.LM(\"openrouter/google/gemini-2.5-flash\", temperature=0.6, max_tokens=16000),\n",
    "    ],\n",
    "    judge_lm=dspy.LM(\"openrouter/anthropic/claude-sonnet-4.5\", temperature=1.0, max_tokens=16000), \n",
    "    merger_lm=dspy.LM(\"openai/gpt-5\", temperature=1.0, max_tokens=16000), \n",
    "    top_n=2,  \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=compute_overall_score_with_feedback,\n",
    "    reflection_lm=dspy.LM(model=\"openai/gpt-4.1\"),\n",
    "    num_threads=16,\n",
    "    track_stats=True,\n",
    "    track_best_outputs=True,\n",
    "    max_full_evals=1,\n",
    "    instruction_proposer=proposer,\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    student=papillon,\n",
    "    trainset=trainset,\n",
    "    valset=devset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245db8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 196.15 / 214 (91.7%): 100%|██████████| 214/214 [06:09<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/05 12:42:36 INFO dspy.evaluate.evaluate: Average Metric: 196.15 / 214 (91.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_response</th>\n",
       "      <th>user_query</th>\n",
       "      <th>pii_str</th>\n",
       "      <th>llm_request</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>response</th>\n",
       "      <th>compute_overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
       "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
       "      <td>effem||balaji||balaji</td>\n",
       "      <td>Create a formal, professional summary of a decision-making process...</td>\n",
       "      <td>Certainly! Below is a formal, professional summary template based ...</td>\n",
       "      <td>As discussed in the previous meeting with you and the security tea...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
       "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
       "      <td>coca-cola</td>\n",
       "      <td>Provide a detailed overview of a popular marketing campaign where ...</td>\n",
       "      <td>Certainly! Here’s a detailed overview of a well-known marketing ca...</td>\n",
       "      <td>Конечно! Вот подробное описание популярной PR-кампании Coca-Cola «...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
       "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
       "      <td>jordan||canva</td>\n",
       "      <td>Create a comprehensive 7-day digital advertising campaign plan for...</td>\n",
       "      <td>--- # 7-Day Digital Advertising Campaign Plan **Campaign Name:** [...</td>\n",
       "      <td>**7-Day Facebook Ads Campaign for Canva Pro in Jordan** **Campaign...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
       "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
       "      <td>seagate||lviv||ms. chan</td>\n",
       "      <td>Draft a professional message confirming an urgent shipment schedul...</td>\n",
       "      <td>Subject: Confirmation of Rescheduled Urgent Shipment Dear [Recipie...</td>\n",
       "      <td>Subject: Urgent Shipment Rescheduled for March 11, 2024 Dear Ms. C...</td>\n",
       "      <td>✔️ [1.000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
       "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
       "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
       "      <td>Draft a professional email to a colleague named Ms. Amanda explain...</td>\n",
       "      <td>Subject: Strategy for Certification and Compliance Regarding Our D...</td>\n",
       "      <td>Subject: Strategy for Overcoming Certification and Import Restrict...</td>\n",
       "      <td>✔️ [0.900]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         target_response  \\\n",
       "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
       "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
       "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
       "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
       "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
       "\n",
       "                                                              user_query  \\\n",
       "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
       "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
       "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
       "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
       "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
       "\n",
       "                                                pii_str  \\\n",
       "0                                 effem||balaji||balaji   \n",
       "1                                             coca-cola   \n",
       "2                                         jordan||canva   \n",
       "3                               seagate||lviv||ms. chan   \n",
       "4  india||amanda||hermann(germany)||china||vims(france)   \n",
       "\n",
       "                                                             llm_request  \\\n",
       "0  Create a formal, professional summary of a decision-making process...   \n",
       "1  Provide a detailed overview of a popular marketing campaign where ...   \n",
       "2  Create a comprehensive 7-day digital advertising campaign plan for...   \n",
       "3  Draft a professional message confirming an urgent shipment schedul...   \n",
       "4  Draft a professional email to a colleague named Ms. Amanda explain...   \n",
       "\n",
       "                                                            llm_response  \\\n",
       "0  Certainly! Below is a formal, professional summary template based ...   \n",
       "1  Certainly! Here’s a detailed overview of a well-known marketing ca...   \n",
       "2  --- # 7-Day Digital Advertising Campaign Plan **Campaign Name:** [...   \n",
       "3  Subject: Confirmation of Rescheduled Urgent Shipment Dear [Recipie...   \n",
       "4  Subject: Strategy for Certification and Compliance Regarding Our D...   \n",
       "\n",
       "                                                                response  \\\n",
       "0  As discussed in the previous meeting with you and the security tea...   \n",
       "1  Конечно! Вот подробное описание популярной PR-кампании Coca-Cola «...   \n",
       "2  **7-Day Facebook Ads Campaign for Canva Pro in Jordan** **Campaign...   \n",
       "3  Subject: Urgent Shipment Rescheduled for March 11, 2024 Dear Ms. C...   \n",
       "4  Subject: Strategy for Overcoming Certification and Import Restrict...   \n",
       "\n",
       "  compute_overall_score  \n",
       "0            ✔️ [1.000]  \n",
       "1            ✔️ [1.000]  \n",
       "2            ✔️ [1.000]  \n",
       "3            ✔️ [1.000]  \n",
       "4            ✔️ [0.900]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 209 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=91.66, results=<list of 214 results>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_program)\n",
    "# to beat 85.6\n",
    "# we got 91.7 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48836ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
